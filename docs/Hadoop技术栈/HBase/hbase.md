# 分布式数据库HBase

## 从 `Big Table`说起

BigTable起初用于解决典型的互联网搜索问题

* **建立互联网索引**
    * 爬虫持续不断地抓取新页面，这些页面每页一行地存储到BigTable里
    * MapReduce计算作业运行在整张表上，生成索引，为网络搜索应用做准备
* **搜索互联网**
    * 用户发起网络搜索请求
    * 网络搜索应用查询建立好的索引，从BigTable得到网页
    * 搜索结果提交给用户

<center><img src='https://cdn.jsdelivr.net/gh/weno861/image/img/202402021329958.png'></center>


## HBase简介

HBase 利用 Hadoop MapReduce 来处理 HBase 中的海量数据，实现高性能计算；利用 ZooKeeper 作为协同服务，实现稳定服务和失败恢复；使用 HDFS 作为高可靠的底层存储，利用廉价集群提供海量数据存储能力。当然，HBase 也可以直接使用本地文件系统而不用 HDFS 作为底层数据存储方式

<center><img src='https://cdn.jsdelivr.net/gh/weno861/image/img/202402021331430.png' alt='Hadoop生态系统'></center>

|              | **BigTable** | **HBase**         |
  | ------------ | ------------ | ----------------- |
  | 文件存储系统 | GFS          | HDFS              |
  | 海量数据处理 | MapReduce    | Hadoop  MapReduce |
  | 协同服务管理 | Chubby       | Zookeeper         |

## HBase与传统关系型数据的对比

HBase 与传统的关系数据库的区别主要体现在以下几个方面

- **数据类型**。关系数据库采用关系模型，具有丰富的数据类型和存储方式。**HBase 则采用了更加简单的数据模型，它把数据存储为未经解释的字符串**，用户可以把不同格式的结构化数据和非结构化数据都序列化成字符串保存到 HBase 中，用户需要自己编写程序把字符串解析成不同的数据类型。
- **数据操作**。关系数据库中提供了丰富的操作，如插入、删除、更新、查询等，其中会涉及复杂的多表连接，通常借助于多个表之间的主外键关联来实现。HBase 提供的操作则不存在复杂的表与表之间的关系，只有简单的插入、查询、删除、清空等。因为 **HBase 在设计上避免了复杂的表与表之间的关系，通常只采用单表的主键查询**，所以它无法实现像关系数据库中那样的表与表之间的连接操作。
- **存储模式**。关系数据库是基于行模式存储的，元组或行会被连续地存储在磁盘页中。在读取数据时，需要顺序扫描每个元组，然后从中筛选出查询所需要的属性。如果每个元组只有少量属性的值对于查询是有用的，那么基于行模式存储就会浪费许多磁盘空间和内存带宽。**HBase 是基于列存储的**，每个列族都由几个文件保存，不同列族的文件是分离的，它的优点是：可以降低 I/O 开销，支持大量并发用户查询（因为仅需要处理可以回答这些查询的列，而不需要处理与查询无关的大量数据行）；同一个列族中的数据会被一起压缩（由于同一列族内的数据相似度较高，因此可以获得较高的数据压缩比）。
- **数据索引**。关系数据库通常可以针对不同列构建复杂的多个索引，以提高数据访问性能。与关系数据库不同的是，**HBase 只有一个索引——行键**，通过巧妙的设计，HBase 中的所有访问方法，或者通过行键访问，或者通过行键扫描，从而使得整个系统不会慢下来。由于 HBase 位于 Hadoop 框架之上，因此可以使用 Hadoop MapReduce 来快速、高效地生成索引表。
- **数据维护**。在关系数据库中，更新操作会用最新的当前值去替换记录中原来的「旧」值，旧值被覆盖后就不会存在。而在 HBase 中执行更新操作时，并不会删除数据的旧的版本，而是**生成一个新的版本**，旧的版本仍然保留。
- **可伸缩性**。关系数据库很难实现横向扩展，纵向扩展的空间也比较有限。相反，HBase 和 BigTable 这些分布式数据库就是为了实现灵活的横向扩展而开发的，因此能够轻易地通过在集群中增加或者减少硬件数量来实现性能的伸缩。

## HBase数据模型

- HBase 是一个**稀疏、多维度、排序的映射表**，这张表的索引包括**行键、列族、列限定符和时间戳**。
- 每个值是一个未经解释的字符串，**没有数据类型**。
- 用户在表中存储数据，每一行都有一个**可排序的行键和任意多的列**。表在水平方向由一个或者多个列族组成，一个列族中可以包含任意多个列，同一个列族里面的数据存储在一起。
- **列族支持动态扩展**，可以很轻松地添加一个列族或列，无须预先定义列的数量以及类型，所有列均以字符串形式存储，用户需要自行进行数据类型转换。由于同一张表里面的每一行数据都可以有截然不同的列，因此对于整个映射表的每行数据而言，有些列的值是空的，所以说 HBase 是稀疏的。
- 在 HBase 中执行更新操作时，并不会删除数据的旧的版本，而是生成一个新的版本，旧的版本仍然保留，HBase 可以对允许保留的版本的数量进行设置

## 数据模型的相关概念

### 表

HBase 采用表来组织数据，表由行和列组成，列划分为若干个列族

### 行键

每个 HBase 表都由若干行组成，每个行由行键（Row Key）来标识。访问表中的行只有 3 种方式：
* 通过单个行键访问
* 通过一个行键的区间来访问
* 全表扫描

### 列族

一个 HBase 表被分组成许多「列族」的集合，它是基本的访问控制单元。列族需要在表创建时就定义好，数量不能太多（HBase 的一些缺陷使得列族的数量只限于几十个），而且不能频繁修改

### 列限定符

列族里的数据通过列限定符（或列）来定位。列限定符不用事先定义，也不需要在不同行之间保持一致。列限定符没有数据类型，总被视为字节数组 byte[]

### 单元格

在 HBase 表中，通过行键、列族和列限定符确定一个「单元格」（Cell）。单元格中存储的数据没有数据类型，总被视为字节数组 byte[]。每个单元格中可以保存一个数据的多个版本，每个版本对应一个不同的时间戳

### 时间戳

每个单元格都保存着同一份数据的多个版本，这些版本采用时间戳进行索引。每次对一个单元格执行操作（新建、修改、删除）时，HBase 都会隐式地自动生成并存储一个时间戳

<center><img src='https://cdn.jsdelivr.net/gh/weno861/image/img/202402021334239.png'></center>

## 数据坐标

HBase 中需要根据行键、列族、列限定符和时间戳来确定一个单元格，因此可以视为一个「四维坐标」，即［「行键」，「列族」，「列限定符」，「时间戳」］

| 键                                            | 值            |      |
|:---:| :---:| --- |
| [“201505003”, “Info”, “email”, 1174184619081] | “xie@qq.com”  |      |
| [“201505003”, “Info”, “email”, 1174184620720] | “you@163.com” |      |


## HBase的实现原理

### HBase功能组件

HBase的实现包括三个主要的功能组件：
* **库函数**：链接到每个客户端
* **一个Master主服务器**
    * 主服务器Master负责管理和维护HBase表的分区信息，维护Region服务器列表，分配Region，负载均衡 
* **许多个Region服务器**
    * Region服务器负责存储和维护分配给自己的Region，处理来自客户端的读写请求 

客户端并不是直接从Master主服务器上读取数据，而是在获得Region的存储位置信息后，直接从Region服务器上读取数据

客户端并不依赖Master，而是通过Zookeeper来获得Region位置信息，大多数客户端甚至从来不和Master通信，这种设计方式使得Master负载很小 

### 表和Region

开始只有一个Region，后来不断分裂
Region拆分操作非常快，接近瞬间，因为拆分之后的Region读取的仍然是原存储文件，直到“合并”过程把存储文件异步地写到独立的文件之后，才会读取新文件

<center><img src='https://cdn.jsdelivr.net/gh/weno861/image/img/202402021342950.png'></center>

### Region的定位

* 元数据表，又名.META.表，存储了Region和Region服务器的映射关系
* 当HBase表很大时， .META.表也会被分裂成多个Region
* 根数据表，又名-ROOT-表，记录所有元数据的具体位置
* -ROOT-表只有唯一一个Region，名字是在程序中被写死
* Zookeeper文件记录了-ROOT-表的位置
* 为了加快访问速度，.META.表的全部Region都会被保存在内存中

<center><img src='https://cdn.jsdelivr.net/gh/weno861/image/img/202402021351750.png'></center>

|**层次**|**名称**|**作用**|
|:---:|:----:|:---:|
| 第一层   | Zookeeper文件 | 记录了-ROOT-表的位置信息                                     |
| 第二层   | -ROOT-表      | 记录了.META.表的Region位置信息  -ROOT-表只能有一个Region。通过-ROOT-表，就可以访问.META.表中的数据 |
| 第三层   | .META.表      | 记录了用户数据表的Region位置信息，.META.表可以有多个Region，保存了HBase中所有用户数据表的Region位置信息 |

## HBase运行机制

### HBase系统架构

1. 客户端
    * 客户端包含访问HBase的接口，同时在缓存中维护着已经访问过的Region位置信息，用来加快后续数据访问过程
2. Zookeeper服务器
    * Zookeeper可以帮助选举出一个Master作为集群的总管，并保证在任何时刻总有唯一一个Master在运行，这就避免了Master的“单点失效”问题
    > Zookeeper是一个很好的集群管理工具，被大量用于分布式计算，提供配置维护、域名服务、分布式同步、组服务等
3. Master
    * 主服务器Master主要负责表和Region的管理工作:
        * 管理用户对表的增加、删除、修改、查询等操作
        * 实现不同Region服务器之间的负载均衡
        * 在Region分裂或合并后，负责重新调整Region的分布
        * 对发生故障失效的Region服务器上的Region进行迁移
4. Region服务器
    * Region服务器是HBase中最核心的模块，负责维护分配给自己的Region，并响应用户的读写请求

<center><img src='https://cdn.jsdelivr.net/gh/weno861/image/img/202402021358500.png'></center>

### Region服务器工作原理

<center><img src='https://cdn.jsdelivr.net/gh/weno861/image/img/202402021521147.png'></center>

#### 用户读写数据过程 

* **写入数据**
    * 用户数据首先被写入到MemStore和Hlog中
    * 用户写入数据时，被分配到相应Region服务器去执行
    * 只有当操作写入Hlog之后，commit()调用才会将其返回给客户端
* **读取数据**
    * 当用户读取数据时，Region服务器会首先访问MemStore缓存，如果找不到，再去磁盘上面的StoreFile中寻找

#### 缓存的刷新

* 系统会**周期性地把MemStore缓存里的内容刷写到磁盘的StoreFile**文件中，清空缓存，并在Hlog里面写入一个标记
* 每次刷新都生成一个新的StoreFile文件，因此，每个Store包含多个StoreFile文件
* 每个Region服务器都有一个自己的HLog 文件，每次启动都检查该文件，确认最近一次执行缓存刷新操作之后是否发生新的写入操作；如果发现更新，则先写入MemStore，再刷写到StoreFile，最后删除旧的Hlog文件，开始为用户提供服务

#### StoreFile的合并

* 每次刷写都生成一个新的StoreFile，数量太多，影响查找速度
* 合并操作比较耗费资源，只有数量达到一个阈值才调用Store.compact()把多个StoreFile合并成一个

### Store工作原理

**Store是Region服务器的核心**

<center><img src='https://cdn.jsdelivr.net/gh/weno861/image/img/202402021526409.png'></center>

### HLog工作原理

分布式环境必须要考虑系统出错。HBase采用HLog保证系统恢复

* **写入操作：** 当客户端发起写入操作（Put、Delete等）时，HBase首先将这些写入操作追加到HLog中。这确保了写入操作在数据存储文件（MemStore）中持久化之前先被记录到HLog中。
* **事务性保障：** HLog的设计是为了提供事务性保障。即使在写入操作尚未持久化到HBase的存储文件之前，HLog中的写入记录已经确保了数据的持久性。在发生故障时，HBase可以通过HLog中的记录来恢复数据。
* **可靠性：** HLog是一个分布式、持久化的写入日志。它通常被存储在HDFS（Hadoop Distributed File System）上，以确保数据的可靠性。HDFS本身提供了高可靠性和容错性，这使得HLog中的写入操作在面对节点故障或其他问题时仍然能够恢复。
* **MemStore 和 HFile：** 一旦写入操作被写入HLog，它们将被写入内存中的MemStore，然后定期或在MemStore大小达到一定阈值时，MemStore的内容将被刷写到HFile，即HBase的数据存储文件。
* **恢复机制：** 在HBase启动时，它会通过读取HLog中的记录来进行数据恢复。即使在节点发生故障并且HBase服务重新启动时，通过HLog中的记录，系统可以重放之前未持久化到存储文件中的写入操作，以确保数据的完整性
